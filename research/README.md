# ðŸ“Š SLE Research â€” DiretÃ³rio de ValidaÃ§Ã£o CientÃ­fica

Este diretÃ³rio reÃºne todos os experimentos, datasets e resultados das validaÃ§Ãµes propostas para o framework **Semantic Latent Engineering (SLE)**.

---

## ðŸ” Estrutura

- `datasets/`  
  > Conjuntos de prompts, outputs, avaliaÃ§Ãµes humanas e automÃ¡ticas usados nos experimentos (E1â€“E5).  
  > Inclui:
  > - SD/HDSA (semantic density vs. qualidade)
  > - ConsistÃªncia ABC
  > - MMOR pipelines

- `experiments/`  
  > Scripts de execuÃ§Ã£o, protocolos experimentais, notebooks Colab/Jupyter para validaÃ§Ã£o de hipÃ³teses SLE.  
  > Cada subpasta/documento contÃ©m:
  > - Objetivo do experimento
  > - HipÃ³tese testada
  > - MÃ©todos (teste, mÃ©tricas, t-test/ANOVA)
  > - ReproduÃ§Ã£o passo a passo

- `results/`  
  > Outputs dos experimentos, tabelas de mÃ©tricas, logs, grÃ¡ficos, e anÃ¡lises estatÃ­sticas.  
  > Inclui:
  > - Resultados brutos e finais
  > - ComparaÃ§Ãµes entre baseline e mÃ©todos SLE
  > - Resumos para publicaÃ§Ã£o/documentaÃ§Ã£o

---

## ðŸ§ª Como Rodar Experimentos

1. Explore a pasta `experiments/` e escolha o protocolo.
2. Confira o dataset apropriado em `datasets/`.
3. Siga o README de cada experimento para reproduzir testes.
4. Consulte resultados, grÃ¡ficos e anÃ¡lises em `results/`.

---

## ðŸ·ï¸ Sobre ValidaÃ§Ã£o

- **Status:** Em andamento. Experimentos preliminares em ambiente limpo foram realizados, mas validaÃ§Ã£o empÃ­rica pÃºblica depende de dataset aberto e colaboraÃ§Ã£o.
- **CritÃ©rio:** Reprodutibilidade, comparabilidade com benchmarks padrÃ£o (baseline X SLE).
- **Como contribuir:** Propor novos datasets, corrigi protocolos, sugerir avaliaÃ§Ãµes diferentes via Pull Request.

---

## ðŸ“š ReferÃªncias  
Consulte o [README central](../README.md) para manifesto, fundamentos e roadmap global.

---

> *"Pesquisa Ã© um processo coletivo. Quem testa, valida â€” quem propÃµe, colabora."*

