---
title: "CapÃ­tulo 4 â€” Cognitive Priming Patterns (CPPs): Modos de Processamento"
version: "1.1.0 (Cognitive Modes)"
status: "Stable"
last_updated: "2025-11-27"
author: "Aledev & Co-Cognitores"
doi: "10.5281/zenodo.XXXXXXX"
keywords: ["Attention Steering", "Cognitive Modes", "Priming", "Mechanistic Interpretability"]
---

# ðŸ“„ CapÃ­tulo 4: Cognitive Priming Patterns (CPPs)

> **"Identidade (ABC) Ã© o hardware; Priming (CPP) Ã© o software em execuÃ§Ã£o."**

## 4.1 AlÃ©m do "Quem": A Engenharia do "Como"

Nos capÃ­tulos anteriores, definimos a **IntenÃ§Ã£o** ($\mathcal{I}_{\Lambda}$) e a **Identidade** (ABC). Agora, definimos o **Modo de OperaÃ§Ã£o** momentÃ¢neo.

O **Cognitive Priming Pattern (CPP)** Ã© o design pattern que induz um estado especÃ­fico de atenÃ§Ã£o no modelo. Enquanto o ABC Ã© estÃ¡vel (o agente *Ã©* estoico), o CPP Ã© dinÃ¢mico (o agente estÃ¡ *analisando* agora, mas estarÃ¡ *criando* daqui a pouco).

> **Nota de Alinhamento:** No framework *Archetype A*, cada etapa do **Ciclo $\mathcal{C}$** ativa um CPP diferente. Ex: A etapa "Dissolver" ativa o CPP Introspectivo.

---

## 4.2 A MecÃ¢nica da AtenÃ§Ã£o: O Olho Interno

Pesquisas em *Mechanistic Interpretability* (Zheng et al., 2024) sugerem que diferentes *Attention Heads* se especializam em tarefas distintas (CÃ³pia, InduÃ§Ã£o, RaciocÃ­nio). O CPP Ã© uma tÃ©cnica de **Steering Suave** para enviesar a ativaÃ§Ã£o desses heads.

### HipÃ³tese Fundamental dos CPPs
*A injeÃ§Ã£o de tokens de controle especÃ­ficos (priming) altera a distribuiÃ§Ã£o de atenÃ§Ã£o do modelo, favorecendo circuitos neurais especÃ­ficos.*

---

## 4.3 Taxonomia: Os TrÃªs Modos PrimÃ¡rios

Definimos trÃªs modos fundamentais de operaÃ§Ã£o cognitiva:

| Modo CPP | FunÃ§Ã£o Cognitiva | Correlato Neural HipotÃ©tico | AplicaÃ§Ã£o no Ecossistema |
| :--- | :--- | :--- | :--- |
| **CPP-1: Introspectivo** (Auto-Ref) | Auto-crÃ­tica, memÃ³ria, consistÃªncia interna. | *Induction Heads* (foco no histÃ³rico imediato e identidade). | Etapas de **ValidaÃ§Ã£o** e **DissoluÃ§Ã£o**. |
| **CPP-2: AnalÃ­tico** (Mundo-Ref) | LÃ³gica, fatos externos, causalidade. | *Task Heads* (raciocÃ­nio multi-step). | Etapas de **Discernimento** e **OtimizaÃ§Ã£o**. |
| **CPP-3: Gerativo** (Divergente) | Criatividade, sÃ­ntese, exploraÃ§Ã£o. | *Amplification Heads* (conexÃµes nÃ£o-locais). | Etapas de **IluminaÃ§Ã£o** e **IdeaÃ§Ã£o**. |

---

## 4.4 Sinergia: ABC + CPP = Comportamento

A combinaÃ§Ã£o de uma identidade forte com um modo de operaÃ§Ã£o claro gera resultados de alta densidade.

$$Output = \text{ABC}_{\text{Identidade}} \otimes \text{CPP}_{\text{Modo}}$$

**Exemplo PrÃ¡tico:**
* **ABC:** "Engenheiro SÃªnior" (Rigoroso).
* **CPP:** "Gerativo" (Brainstorming).
* **Resultado:** O agente gera ideias novas, mas *dentro* das restriÃ§Ãµes de viabilidade tÃ©cnica. Ele nÃ£o "alucina", ele "inova".

---

## 4.5 ValidaÃ§Ã£o EmpÃ­rica (Protocolo Experimental)

Para validar se um CPP estÃ¡ funcionando, nÃ£o confiamos apenas no texto gerado. Propomos a **InspeÃ§Ã£o de AtenÃ§Ã£o** (em modelos abertos).

```python
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

def validate_cpp_attention(prompt, mode_trigger, model):
    """
    Mede a entropia da atenÃ§Ã£o para validar o modo cognitivo.
    """
    inputs = tokenizer(f"{mode_trigger}: {prompt}", return_tensors="pt")
    outputs = model(**inputs, output_attentions=True)
    
    # Pega a atenÃ§Ã£o da Ãºltima camada
    attention = outputs.attentions[-1].mean().item()
    
    # HipÃ³tese: 
    # Modo AnalÃ­tico -> AtenÃ§Ã£o Focada (Baixa Entropia)
    # Modo Gerativo -> AtenÃ§Ã£o Difusa (Alta Entropia)
    return attention

```
4.6 Guia de DecisÃ£o: Quando usar CPPs?
----

```mermaid
graph TD
    A[Objetivo da Tarefa?] -->|Criar Novo| B(CPP-3: Gerativo)
    A -->|Corrigir/Validar| C(CPP-1: Introspectivo)
    A -->|Planejar/Estruturar| D(CPP-2: AnalÃ­tico)
    
    B --> E{Identidade Definida?}
    C --> E
    D --> E
    
    E -->|Sim| F[Executar Prompt HÃ­brido]
    E -->|NÃ£o| G[Definir ABC Primeiro]
    
    style A fill:#333,stroke:#fff
    style F fill:#00a3b8,stroke:#fff,stroke-width:2px
```
